{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_rating_matrix():\n",
    "    ratings = pd.read_csv('Purchases.csv')\n",
    "    \n",
    "    # of customers\n",
    "    m = ratings['Customer_ID'].max() + 1\n",
    "    \n",
    "    # of products\n",
    "    n = ratings['Product_ID'].max() + 1\n",
    "    \n",
    "    #matrix of ratings\n",
    "    m1 = np.zeros((m,n))\n",
    "    \n",
    "    i = ratings[:]['Customer_ID']\n",
    "    j = ratings[:]['Product_ID']\n",
    "    \n",
    "    m1[i, j] = 1\n",
    "       \n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_feature_matrix():\n",
    "    customer_features = pd.read_csv('Customer_Features.csv')\n",
    "    # convert into numpy array of m rows, n columns\n",
    "    a = customer_features.as_matrix()\n",
    "    \n",
    "    product_features = pd.read_csv('Product_Features.csv')\n",
    "    b = product_features.as_matrix()\n",
    "    \n",
    "    return a[:, 1:], b[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 284)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B = prepare_feature_matrix()\n",
    "m1 = prepare_rating_matrix()\n",
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#next steps\n",
    "# efficient way of doing test-train split using np.axis\n",
    "#train the model\n",
    "#efficient way of doing eval - AUC\n",
    "#run model and get result\n",
    "\n",
    "#set up langragian formulation - splitting m,n\n",
    "#set up RDD datapreparation, training and eval\n",
    "   #data preparation - map actual id to serial id \n",
    "   #efficient test-train split\n",
    "\n",
    "#run model on databricks and get result\n",
    "#run model on AWS and compare running time for different values of k = # of nodes\n",
    "#document and upload on Github and we are done!!!!\n",
    "\n",
    "#https://stackoverflow.com/questiohttps://stackoverflow.com/questions/13272453/multiplying-numpy-scipy-sparse-and-dense-matrices-efficientlyns/13272453/multiplying-numpy-scipy-sparse-and-dense-matrices-efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utility to flag certain purchases for testing, prepare the weighting matrix\n",
    "def remove_purchases(vector, fraction):\n",
    "    d = len(vector) // 2\n",
    "    tmp_m1  = vector[:d]\n",
    "    C = vector[d:]\n",
    "    s = np.sum(tmp_m1)\n",
    "    sample = int(s*fraction)\n",
    "    if ((s > 0) & (sample > 0)):\n",
    "        shape = tmp_m1.shape\n",
    "        p = np.full(shape,1.0)\n",
    "        p[tmp_m1 == 0] = 0\n",
    "        valid = tmp_m1[tmp_m1 > 0].size\n",
    "        p = p/valid\n",
    "        inds = np.random.choice(tmp_m1.size, sample, replace = False, p = p)\n",
    "        C[inds] = -2\n",
    "    return np.concatenate((tmp_m1, C))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_weighting_matrix(m1, alpha = 40, fraction = .2): \n",
    "    #alpha adjusts weighting between purchases, non-purchases\n",
    "    #fraction determines percent of purchases for each customer that needs to be set aside for testing and not used during training\n",
    "    C = m1*alpha + 1\n",
    "    x = np.hstack((m1, C))\n",
    "    mat =  np.apply_along_axis(lambda vector: remove_purchases(vector, fraction), 1, x)\n",
    "    d = mat.shape[1] // 2\n",
    "    return (mat[:, :d], mat[:, d:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 284)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1, C = prepare_weighting_matrix(m1)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params(m1, C, A, B, f):\n",
    "    m = m1.shape[0] #get rows\n",
    "    n = m1.shape[1] #get columns\n",
    "    \n",
    "    assert A.shape[0] ==   m, \"customer feature dimension incompatibility\"\n",
    "    assert B.shape[0] == n,  \"product feature dimension incompatibility\"\n",
    "    \n",
    "    k = A.shape[1]\n",
    "    l = B.shape[1]\n",
    "    \n",
    "    #initialize trainable parameters\n",
    "    X = np.random.randn(m, f) #m*f matrix for user latent factors\n",
    "    Y = np.random.randn(n, f) #n*f matrix for item latent factors\n",
    "    D = np.random.randn(l, f) #embedding to transform item features into the f-dimensional factor space\n",
    "    G = np.random.randn(k, f) #embedding to transform user features into the f-dimensional factor space\n",
    "    d = np.random.randn(l) #embedding to transform item features into the f-dimensional factor space\n",
    "    g = np.random.randn(k) #embedding to transform user features into the f-dimensional factor space\n",
    "    Bias_user = np.random.randn(m) #bias for m users\n",
    "    Bias_item = np.random.randn(n) #bias for n users\n",
    "    \n",
    "    return X, Y, D, G, d, g, Bias_user, Bias_item\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, D, G, d, g, Bias_user, Bias_item = initialize_params(m1, C, A, B, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_user_factors(m1, C, A, B, L, X, Y, D, G, d, g, Bias_user, Bias_item, f):\n",
    "    B_ = np.matmul(B, D)\n",
    "    for u in range(0, m1.shape[0]):\n",
    "            Filter = C[u,:]            #apply the filter to the inputs before updating the customer's parameters\n",
    "            p_u = m1[u, :]\n",
    "            p_u = p_u[Filter > -1]            \n",
    "            alpha_u = A[u,:]                      \n",
    "            term1 = np.matmul(Y + B_, np.matmul(alpha_u, G))\n",
    "            term1 = term1[Filter > -1]            \n",
    "            term2 = np.matmul(B, d)\n",
    "            term2 = term2[Filter > -1]            \n",
    "            term3 = np.matmul(g, alpha_u)            \n",
    "            term4 = Bias_item[Filter > -1]            \n",
    "            p_u = p_u  - term1 - term2  - term3 - term4\n",
    "            \n",
    "            n_adj = p_u.size\n",
    "            temp = C[u, :]\n",
    "            temp = temp[temp > -1]\n",
    "            c_u = temp*np.eye(n_adj) \n",
    "            \n",
    "            ones = np.ones((n_adj, 1))\n",
    "            Yadj = Y + B_\n",
    "            Yadj = Yadj[Filter > -1, :]            \n",
    "            Yadj = np.concatenate((Yadj, ones), axis = 1)\n",
    "            \n",
    "            \n",
    "            I_x = L*np.eye(f + 1)\n",
    "                        \n",
    "            #Implement equation 1\n",
    "            step1 = np.matmul(Yadj.T, (np.matmul(c_u,Yadj))) + I_x\n",
    "            step2 = inv(step1)\n",
    "            updates = np.matmul(step2, np.matmul(Yadj.T, np.matmul(c_u, p_u)))\n",
    "            #print (updates.shape)\n",
    "            \n",
    "            X[u,:] = updates[:f]\n",
    "            Bias_user[u] = updates[f:]\n",
    "            \n",
    "            #print ('%s %d' % ('Updated factors for user #: ', u+1))            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_item_factors(m1, C, A, B, L, X, Y, D, G, d, g, Bias_user, Bias_item, f):\n",
    "    A_ = np.matmul(A, G)\n",
    "    for i in range(0, m1.shape[1]):\n",
    "        Filter = C[:,i]            #apply the filter to the inputs before updating the item's parameters\n",
    "        p_i = m1[:, i]\n",
    "        p_i = p_i[Filter > -1]   \n",
    "        beta_i = B[i,:]                      \n",
    "        term1 = np.matmul(X + A_, np.matmul(beta_i, D))\n",
    "        term1 = term1[Filter > -1]            \n",
    "        term2 = np.matmul(A, g)\n",
    "        term2 = term2[Filter > -1]            \n",
    "        term3 = np.matmul(d, beta_i)            \n",
    "        term4 = Bias_user[Filter > -1]            \n",
    "        p_i = p_i  - term1 - term2  - term3 - term4\n",
    "        \n",
    "        n_adj = p_i.size\n",
    "        temp = C[:, i]\n",
    "        temp = temp[temp > -1]\n",
    "        c_i = temp*np.eye(n_adj) \n",
    "        \n",
    "        ones = np.ones((n_adj, 1))\n",
    "        Xadj = X + A_\n",
    "        Xadj = Xadj[Filter > -1, :]            \n",
    "        Xadj = np.concatenate((Xadj, ones), axis = 1)\n",
    "        \n",
    "        I_y = L*np.eye(f + 1)\n",
    "        \n",
    "        #update user factors, user bias\n",
    "        step1 = np.matmul(Xadj.T, (np.matmul(c_i,Xadj))) +I_y\n",
    "        step2 = inv(step1)\n",
    "        updates = np.matmul(step2, np.matmul(Xadj.T, np.matmul(c_i, p_i)))\n",
    "        #print (updates.shape)\n",
    "            \n",
    "        Y[i,:] = updates[:f]\n",
    "        Bias_item[i] = updates[f:]\n",
    "            \n",
    "        #print ('%s %d' % ('Updated factors for item #: ', i+1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_customer_embedding(m1, C, A, B, L_G, X, Y, D, G, d, g, Bias_user, Bias_item, f):\n",
    "        \n",
    "    m = m1.shape[0]\n",
    "    n = m1.shape[1]\n",
    "    k = A.shape[1]\n",
    "    l = B.shape[1]\n",
    "      \n",
    "    B_ = np.matmul(B, D) + Y\n",
    "    Y_ = np.tensordot(A, B_, axes = 0)   \n",
    "    Y_ = np.swapaxes(Y_, 1, 2)    \n",
    "    Y_ = np.reshape(Y_, (m, n, -1))\n",
    "    \n",
    "    \n",
    "    X_ = np.matmul(X, B_.T)    \n",
    "    Bu = np.expand_dims(Bias_user, axis = 1)\n",
    "    Bi = np.expand_dims(Bias_item, axis = 0)\n",
    "    \n",
    "    m1_adj = m1  -  Bi -  np.expand_dims(np.matmul(B, d), axis = 0)  - Bu - X_\n",
    "    \n",
    "    A_ = np.zeros((m,n,k)) + np.expand_dims(A, axis = 1)\n",
    "    Y_ = np.concatenate((Y_, A_), axis = 2)\n",
    "    \n",
    "    Y_ = np.reshape(Y_, (m*n, -1))\n",
    "    C_ = np.squeeze(np.reshape(C, (m*n, -1)))\n",
    "    m1_adj = np.squeeze(np.reshape(m1_adj, (m*n, -1)))\n",
    "    Filter = C_\n",
    "    \n",
    "\n",
    "    C_adj = C_[Filter > -1]    \n",
    "    n_adj = C_adj.size\n",
    "    \n",
    "    C_ui = sparse.csr_matrix.multiply(sparse.eye(n_adj), C_adj)\n",
    "    p = m1_adj[Filter > -1]\n",
    "    Y_ = Y_[Filter > -1, :]\n",
    "   \n",
    "    \n",
    "    I_G = L_G*np.eye(k*f + k)\n",
    "    \n",
    "    step1 = np.matmul(Y_.T, C_ui.dot(Y_)) + I_G\n",
    "    step2 = inv(step1)\n",
    "    updates = np.matmul(step2, np.matmul(Y_.T, C_ui.dot(p)))\n",
    "    \n",
    "    G = np.reshape(updates[:k*f],(k,f))\n",
    "    g = updates[-k:]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_item_embedding(m1, C, A, B, L_D, X, Y, D, G, d, g, Bias_user, Bias_item, f):    \n",
    "    \n",
    "    m = m1.shape[0]\n",
    "    n = m1.shape[1]\n",
    "    k = A.shape[1]\n",
    "    l = B.shape[1]\n",
    "    \n",
    "    A_ = np.matmul(A, G) + X\n",
    "    X_ = np.tensordot(A_, B, axes = 0)\n",
    "    X_ = np.swapaxes(X_, 1, 2) \n",
    "    X_ = np.swapaxes(X_, 2, 3) \n",
    "    X_ = np.reshape(X_, (m, n, -1))\n",
    "    \n",
    "    Y_ = np.matmul(A_, Y.T)    \n",
    "    Bu = np.expand_dims(Bias_user, axis = 1)\n",
    "    Bi = np.expand_dims(Bias_item, axis = 0)\n",
    "    m1_adj = m1  -  Bi -  np.expand_dims(np.matmul(A, g), axis = 1)  - Bu - Y_\n",
    "    \n",
    "   \n",
    "    B_ = np.zeros((m,n,l)) + np.expand_dims(B, axis = 0)\n",
    "    X_ = np.concatenate((X_, B_), axis = 2)\n",
    "    \n",
    "    X_ = np.reshape(X_, (m*n, -1))\n",
    "    C_ = np.squeeze(np.reshape(C, (m*n, -1)))\n",
    "    m1_adj = np.squeeze(np.reshape(m1_adj, (m*n, -1)))\n",
    "    Filter = C_\n",
    "    \n",
    "    C_adj = C_[Filter > -1]    \n",
    "    n_adj = C_adj.size\n",
    "    \n",
    "    C_ui = sparse.csr_matrix.multiply(sparse.eye(n_adj), C_adj)\n",
    "    p = m1_adj[Filter > -1]\n",
    "    X_ = X_[Filter > -1, :]\n",
    "    \n",
    "    I_D = L_D*np.eye(l*f + l)\n",
    "    \n",
    "    step1 = np.matmul(X_.T, C_ui.dot(X_)) + I_D\n",
    "    step2 = inv(step1)\n",
    "    updates = np.matmul(step2, np.matmul(X_.T, C_ui.dot(p)))\n",
    "    \n",
    "    D = np.reshape(updates[:l*f],(l,f))\n",
    "    d = updates[-l:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#core model training based on Alternating Least Squares (ALS)\n",
    "# f is the number of latent factors to estimate per customer, product\n",
    "#Sweeps specifies # of iterations until convergence\n",
    "def modeltrain(m1, C, A, B, L_U = 2, L_I = 2, L_G = 2, L_D = 2, f = 20, sweeps = 10):    \n",
    "\n",
    "    X, Y, D, G, d, g, Bias_user, Bias_item =  initialize_params(m1, C, A, B, f)\n",
    "    #Each sweep comprises an update of user factors, item factors, user/item feature to factor embedding\n",
    "    for itr in range(0, sweeps):\n",
    "        print ('%s %d' % ('Starting iteration #: ', itr + 1))  \n",
    "        update_user_factors(m1, C, A, B, L_U, X, Y, D, G, d, g, Bias_user, Bias_item, f)\n",
    "        update_item_factors(m1, C, A, B, L_I, X, Y, D, G, d, g, Bias_user, Bias_item, f)\n",
    "        update_customer_embedding(m1, C, A, B, L_G, X, Y, D, G, d, g, Bias_user, Bias_item, f)\n",
    "        update_item_embedding(m1, C, A, B, L_D, X, Y, D, G, d, g, Bias_user, Bias_item, f)     \n",
    "    return X, Y, D, G, d, g, Bias_user, Bias_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration #:  1\n",
      "Starting iteration #:  2\n",
      "Starting iteration #:  3\n",
      "Starting iteration #:  4\n",
      "Starting iteration #:  5\n",
      "Starting iteration #:  6\n",
      "Starting iteration #:  7\n",
      "Starting iteration #:  8\n",
      "Starting iteration #:  9\n",
      "Starting iteration #:  10\n"
     ]
    }
   ],
   "source": [
    "X, Y, D, G, d, g, Bias_user, Bias_item = modeltrain(m1, C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictions(X, Y, D, G, d, g, Bias_user, Bias_item, A, B): #returns m by n dense matrix of predictions\n",
    "    temp1 = np.matmul((np.matmul(A,G) + X), (np.matmul(B,D) + Y).T)\n",
    "    temp2 = np.expand_dims(np.matmul(A,g), axis = 1)\n",
    "    temp3 = np.expand_dims(np.matmul(B,d), axis = 0)\n",
    "    return temp1 + temp2 + temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 284)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predictions(X, Y, D, G, d, g, Bias_user, Bias_item, A, B)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeleval_AUC(m1, C, pred1):\n",
    "    result = 0.0   \n",
    "    m = m1.shape[0]   \n",
    "    count = 0\n",
    "    for i in range(0,m):\n",
    "        num = 0\n",
    "        pred2 = pred1[i,:]\n",
    "        preds = pred2[(m1[i,:] == 0) & (C[i,:] > 0)]\n",
    "        testscore = pred2[C[i,:] == -2]\n",
    "        l = testscore.size\n",
    "        if ((l > 0) & (preds.size > 0)):\n",
    "            for j in range(0,l):\n",
    "                temp = testscore[j] - preds\n",
    "                num = num + sum(temp > 0)\n",
    "            result = result + float(num)/float(preds.size*l)\n",
    "            count = count + 1 \n",
    "        \n",
    "    return (result/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965624443080479"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeleval_AUC(m1, C, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
