{"cells":[{"cell_type":"code","source":["import numpy as np\n \ndef create_matrices(Tuple, values, alpha, c, p, M, N):\n  m = M // c + 1*(M % c > 0)\n  n = N // p + 1*(N % p > 0)\n  i = Tuple[0]\n  j = Tuple[1]\n \n  if i < (c-1):\n    x1 = m\n  else:\n    x1 = M - m*(c-1)\n    \n  if j < (p-1):\n    x2 = n\n  else:\n    x2 = N - n*(p-1)\n  \n  m1 = np.zeros([x1, x2], dtype=np.int64)\n  y1 = [t[0] for t in values]\n  y2 = [t[1] for t in  values]\n  m1[y1, y2] = 1\n  C = 1 + m1*alpha\n  return (((Tuple), (m1, C)))\n   \n  \n#create m1 and C matrices\ndef create_m1_C(data, c, p, M, N, alpha):\n  numpartitions = c*p\n  m1 = M // c + 1*(M % c > 0)\n  n1 = N // p + 1*(N % p > 0)\n  entries = data.map(lambda x: ((x[0] // m1, x[1] // n1), (x[0] % m1, x[1] % n1 ))).partitionBy(numpartitions, lambda x: x[0]*p + x[1])\n  return  (entries.groupByKey().map(lambda x :create_matrices(x[0], x[1], alpha, c, p, M, N )))\n \n\n#placeholder for splitting customers and products. \n#use Lagrangian multipliers for the general case of N being as large as M\ndef lang_opt(k, M, N):\n  return ((k // 3  , 3))\n\n#load purchase data to create the RDD of m1 and C submatrices.\n#alpha is weighting parameter, f is rank (no of latent factors to fit)\n#numpartitions is number of partitions to divide data into \n\n#def load_ratings(alpha, numpartitions, f, Lambda):\ndef load_ratings(alpha, numpartitions):\n  data = sc.textFile(\"/FileStore/tables/mf8ppr9o1486658249082/Customer_Purchases3.csv\")\n  header = data.first() #extract header\n  data = data.filter(lambda row : row != header) \n  data = data.map(lambda l: l.split(\",\")).map(lambda x: (int(x[0]) -1, int(x[1]) -1))\n  \n  N = data.map(lambda x: x[1]).top(1)[0] + 1\n  M = data.map(lambda x: x[0]).top(1)[0] + 1\n  partitions = lang_opt(numpartitions, M, N)\n  c = partitions[0]\n  p = partitions[1]\n  m = M // c + 1*(M % c > 0)\n  n = N // p + 1*(N % p > 0)\n  matrices = create_m1_C(data, c, p, M, N, alpha).persist()\n  return ([matrices, [c,p,M,N, m, n]])\n  \ndef flatten2(x):\n  p = partition_params.value[1]\n  m = partition_params.value[4]\n  return ([((int(x[0]-1) // m, i),  (int(x[0]-1) % m, x[1:])) for i in range(p)])\n\ndef flatten3(x):\n  c = partition_params.value[0]\n  n = partition_params.value[5]\n  return ([((i,int(x[0]-1) // n),  (int(x[0]-1) % n, x[1:])) for i in range(c)])\n\n  \n\ndef create_vecs(values):\n  sorted_values = sorted(values, key = (lambda x: x[0]))\n  vecs = [t[1] for t in  sorted_values]\n  return (np.array(vecs))\n\n#Load customer features as per the existing partition\ndef load_customer_features(matrices):\n  customer_data = sc.textFile(\"/FileStore/tables/f11biiqi1486887764969/Customer_Features.csv\")\n  header = customer_data.first() #extract header\n  customer_data = customer_data.filter(lambda row : row != header) \n  customer_data = customer_data.map(lambda l: l.split(\",\")).map(lambda x: map(float, x))\n  customer_data = customer_data.flatMap(lambda  x: flatten2(x))\n  a = customer_data.groupByKey().mapValues(create_vecs)\n  a = matrices.join(a).mapValues(lambda x: x[1]).persist()\n  cust_len = a.lookup((0,0))[0].shape[1]\n  return ([a, cust_len])\n\n#Load customer features as per the existing partition\ndef load_product_features(matrices):\n  product_data = sc.textFile(\"/FileStore/tables/zqjp4ejm1486897287081/Product_Features.csv\")\n  header = product_data.first() #extract header\n  product_data = product_data.filter(lambda row : row != header) \n  product_data = product_data.map(lambda l: l.split(\",\")).map(lambda x: map(float, x))\n  product_data = product_data.flatMap(lambda  x: flatten3(x))\n  b = product_data.groupByKey().mapValues(create_vecs)\n  b = matrices.join(b).mapValues(lambda x: x[1]).persist()\n  prod_len = b.lookup((0,0))[0].shape[1]\n  return ([b, prod_len])\n\n  \n  "],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def generate_factors(vals):\n  c = vals[0]\n  m = vals[1]\n  M = vals[2]\n  i = vals[3]\n  f = vals[4] + vals[5]\n  if i < (c-1):\n    x = m\n  else:\n    x = M - m*(c-1)\n  return ((i, np.random.randn(x,f)))\n\n\n  \ndef propagate_customer_factors(matrices, y):\n  p = partition_params.value[1]\n  y = sc.parallelize(y).flatMap(lambda x: [((x[0], i), (x[1])) for i in range(p)])\n  return (matrices.join(y).mapValues(lambda x: x[1]))\n\ndef propagate_product_factors(matrices, y):\n  c = partition_params.value[0]\n  y = sc.parallelize(y).flatMap(lambda x: [((i, x[0]), (x[1])) for i in range(c)])\n  return (matrices.join(y).mapValues(lambda x: x[1]))\n  \ndef initialize_customer_factors(matrices):\n  c = partition_params.value[0]\n  M = partition_params.value[2]\n  m = partition_params.value[4]\n  f_ = f.value\n  vals  = [(c, m, M, i, f_, prod_len.value) for i in range(c)]\n  y = list(map(lambda x: generate_factors(x), vals))\n  return (propagate_customer_factors(matrices, y))\n\n  \n  \ndef initialize_product_factors(matrices):\n  p = partition_params.value[1]\n  N = partition_params.value[3]\n  n = partition_params.value[5]\n  f_ = f.value\n  vals  = [(p, n, N, i, f_, cust_len.value) for i in range(p)]\n  y = list(map(lambda x: generate_factors(x), vals))\n  return (propagate_product_factors(matrices, y))\n\n\n  \n  "],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from numpy.linalg import inv\n\ndef update_customer_messages(matrices, yblock, a, b):\n  y = yblock.mapValues(lambda x: x[:, :f.value])\n  yy = yblock.mapValues(lambda x: x[:, f.value:])\n  y_aug = y.join(yy).join(b)\n  msg = matrices.mapValues(lambda x: np.hstack((x[0], x[1]))).join(a).join(y_aug).mapValues(lambda x : update(x, cust_len.value))\n  return msg\n  \ndef update(values, dim):\n  #extract  relavent values\n  y = values[1][0][0]\n  b = values[1][1]\n  y_o = np.hstack((y,b))\n  x1 = values[0][0]\n  yy = values[1][0][1]\n  a = values[0][1]\n  x2 = np.hstack((x1,a))\n  return np.apply_along_axis(lambda x: update_msg_axis(x, y_o, yy, dim), 1, x2)\n\ndef update_msg_axis(vector, y_o,  yy, dim):\n  d = (len(vector) - dim) // 2 #this is the same as f\n  Filter = vector[d : 2*d]\n  p_u = vector[:d]\n  p_u = p_u[Filter > -1]\n  n_adj = p_u.size\n  temp = Filter[Filter > -1]\n  c_u = temp*np.eye(n_adj) \n  \n  a_u = vector[-dim:]\n  yy_adj = yy[Filter > -1, :]\n  pu_corr =np.dot(yy_adj, a_u) \n  p_u = p_u - pu_corr\n  y_o_filter = y_o[Filter > -1,:]\n\n  #update all the messages\n  msg1 = np.dot(y_o_filter.T, np.dot(c_u, p_u)).T\n  msg2 = np.dot(y_o_filter.T, np.dot(c_u, y_o_filter)).ravel()\n  #retunrs the flatenned matrices of dimenion 1 X [f*f +f]\n  return (np.hstack((msg2, msg1)))\n\ndef update_customerfactors(x):\n  return np.apply_along_axis(lambda vec: compute_factors(vec, prod_len.value), 1, x)\n                                                              \ndef compute_factors(vec, dim):\n  f_ = dim + f.value\n  Lambda_ = Lambda.value\n  x1 = vec[:-f_]\n  \n  x1 = x1.reshape(f_,-1)\n  x2 = vec[-f_:]\n \n  temp = inv(x1 + Lambda_*np.eye(f_))\n  val = np.dot(temp,x2.T).T\n  return val\n\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["def reduce_propagate_customer_messages(msgs):\n  c = partition_params.value[0]\n  vals  = range(c)\n  y = list(map(lambda x: reduce_cust_msg(x, msgs), vals))\n  return (propagate_customer_factors(matrices, y))\n\n\ndef reduce_cust_msg(vals, msgs):\n  #use i to filter msgs and then reduce to get final value which is passed\n  msgs_reduced = msgs.filter(lambda x: x[0][0] == vals).map(lambda x: x[1]).reduce(lambda x,y: x + y)\n  factors = update_customerfactors(msgs_reduced)\n  return ((vals, factors))\n\ndef CustomerFactor_Update(msgs):\n  p = partition_params.value[1] \n  if p < 2:\n    return msgs.mapValues(lambda x: update_customerfactors(x))\n  else:\n    return reduce_propagate_customer_messages(msgs)\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from numpy.linalg import inv\n\ndef update_product_messages(matrices, xblock, a, b):\n  x = xblock.mapValues(lambda x: x[:, :f.value])\n  xx = xblock.mapValues(lambda x: x[:, f.value:])\n  x_aug = x.join(xx).join(a)\n  msg = matrices.mapValues(lambda x: np.vstack((x[0], x[1]))).mapValues(lambda x :  x.T).join(b).join(x_aug).mapValues(lambda x : update(x, prod_len.value))\n  return msg\n  \n\n\ndef update_productfactors(x):\n  return np.apply_along_axis(lambda vec: compute_factors(vec, cust_len.value), 1, x)\n                                                              \n\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["def reduce_propagate_product_messages(msgs):\n  p = partition_params.value[1]\n  vals  = range(p)\n  y = list(map(lambda x: reduce_prod_msg(x, msgs), vals))\n  return (propagate_product_factors(matrices, y))\n\n\ndef reduce_prod_msg(vals, msgs):\n  #use i to filter msgs and then reduce to get final value which is passed\n  msgs_reduced = msgs.filter(lambda x: x[0][1] == vals).map(lambda x: x[1]).reduce(lambda x,y: x + y)\n  factors = update_productfactors(msgs_reduced)\n  return ((vals, factors))\n\ndef ProductFactor_Update(msgs):\n  c = partition_params.value[0] \n  if c < 2:\n    return msgs.mapValues(lambda x: update_productfactors(x))\n  else:\n    return reduce_propagate_product_messages(msgs)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["def model_training(matrices, a, b, sweeps):\n  #f = sc.broadcast(f_)\n  #Lambda = sc.broadcast(Lambda_)\n  \n  #inititalize, propagate the customer and product factors\n  xblock = initialize_customer_factors(matrices).persist()\n  yblock = initialize_product_factors(matrices).persist()\n  \n  for k in range(sweeps):\n    msg = '%s %d' % ('Starting iteration #: ', k)  \n    print msg\n        \n    # update customer factors\n    msgs = update_customer_messages(matrices, yblock, a, b).persist()\n    xblock = CustomerFactor_Update(msgs).persist()\n    print xblock.count()\n    msg = 'Completed update of customer factors' \n    print msg\n    \n    # update product factors\n    msgs = update_product_messages(matrices, xblock, a, b).persist()\n    yblock = ProductFactor_Update(msgs).persist()\n    print yblock.count()\n    msg = 'Completed update of product factors' \n    print msg\n  \n  return ([xblock, yblock])\n  \n  \n  \n  "],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#split into test-train\n#some of the purchases are marked fore testing and removed from training\n#C[i,j] == -2 indicates that that that data-point has been flagged for testing\n#sample is number of purchases per customer that must be flagged for testing\n#k is threshold parameter; if customer has < k purchases, then none of his purchases flagged for testing\n#use this if model is evaluated for AUC\ndef data_test_train(matrices, fraction):\n  return matrices.mapValues(lambda x: test_train_split(x, fraction))\n\ndef test_train_split(x, fraction):\n    m1 = x[0]\n    C = x[1]\n    x1 = np.hstack((m1, C))\n    mat =  np.apply_along_axis(lambda vector: remove_purchases_axis(vector, fraction), 1, x1)\n    d = mat.shape[1] // 2\n    return (mat[:, :d], mat[:, d:])\n  \ndef remove_purchases_axis(vector, fraction):\n    d = len(vector) // 2\n    tmp_m1  = vector[:d]\n    C = vector[d:]\n    s = np.sum(tmp_m1)\n    sample = int(s*fraction)\n    if (sample > 0):\n      shape = tmp_m1.shape\n      p = np.full(shape,1.0)\n      p[tmp_m1 == 0] = 0\n      valid = tmp_m1[tmp_m1 > 0].size\n      p = p/valid\n      inds = np.random.choice(tmp_m1.size, sample, replace=False, p = p)\n      C[inds] = -2\n    return np.concatenate((tmp_m1, C), axis=1)\n      \n\n\n\n\n        \n\n    \n    \n\n\n  "],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#load the ratings data to create the matrices RDD\n[matrices, partition_params] = load_ratings(40, 36)\npartition_params = sc.broadcast(partition_params) #broadcast partition_params to all worker nodes\n\n\n[a, cust_len] = load_customer_features(matrices)\nprint cust_len\ncust_len = sc.broadcast(cust_len)\n[b, prod_len] = load_product_features(matrices)\nprint prod_len\nprod_len = sc.broadcast(prod_len)\n\nmatrices = data_test_train(matrices, 0.5).persist()\nf = sc.broadcast(10)\nLambda = sc.broadcast(10)\n[xblock, yblock] = model_training(matrices, a, b, 10)\nprint xblock.lookup((0,0))[0].shape\nprint xblock.lookup((0,2))[0]\n\nprint yblock.lookup((0,0))[0].shape\nprint yblock.lookup((0,2))[0]\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["def predictions(a, b, xblock, yblock):\n  x = xblock.mapValues(lambda x: x[:, :f.value])\n  xx = xblock.mapValues(lambda x: x[:, f.value:])\n  XX_ = x.join(a).mapValues(lambda x: np.hstack((x[0], x[1])))\n  XX = XX_.join(xx).mapValues(lambda x: np.hstack((x[0], x[1])))\n  YY = yblock.join(b).mapValues(lambda x: np.hstack((x[0], x[1])))\n  return (XX.join(YY).mapValues(lambda x: np.dot(x[0], x[1].T)))\n  \n \n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["def modeleval_AUC(pred1, matrices):\n  c = partition_params.value[0]\n  vals  = range(c)\n  y = list(map(lambda x: reduce_along_p(x, pred1, matrices), vals))\n  y = sc.parallelize(y)\n  y = y.map(lambda x: arbit(x)).map(lambda x: np.array(x))\n  final = y.reduce(lambda x, y: x+ y)\n  #ind = y[:,-1]\n  ##inds = sum(ind > 0)\n  #yy = y[:, 0:2]\n  #final = np.apply_along_axis(lambda x: x[0]/x[1], 1, yy)\n  return final[0]/final[1]\n  #return final\n\ndef eval(x):\n  m1 = x[0][0]\n  C = x[0][1]\n  pred1 = x[1]\n  x1 = np.hstack((np.hstack((m1,C)), pred1))\n  return  np.apply_along_axis(lambda vector: eval_axis(vector), 1, x1)\n  \ndef arbit(x):\n  kk1 = np.array(x)\n \n  dim = kk1.shape[1]\n  kk2 = kk1.reshape(dim,-1)\n  \n  ind = kk2[:,-1]\n  inds = sum(ind > 0)\n  yy = kk2[:, 0:2]\n  final = np.sum(np.apply_along_axis(lambda x: kaka(x), 1, yy))\n  return np.array([final, inds])\n\ndef kaka(x):\n  if x[1] > 0:\n    return x[0]/x[1]\n  else:\n    return 0\n  \ndef eval_axis(vector):\n  d = len(vector) // 3\n  num =0\n  m1 = vector[:d]\n  C = vector[d:2*d]\n  pred2 = vector[2*d:]\n  preds = pred2[(m1 == 0) & (C > 0)]\n  testscore = pred2[C == -2]\n  l = testscore.size\n  result1 = 0\n  result2 = 0\n  count = 0\n  if ((l > 0) & (preds.size > 0)):\n    for j in range(0,l):\n                temp = testscore[j] - preds\n                num = num + sum(temp > 0)\n    result1 = float(num)\n    result2 = float(preds.size*l)\n    count = count +1\n    \n  return (result1, result2, count)\n\n\n\n  \n\n\ndef reduce_along_p(vals, pred1, matrices):\n  #use i to filter msgs and then reduce to get final value which is passed\n  pred_ = pred1.filter(lambda x: x[0][0] == vals)\n  matrices_ = matrices.filter(lambda x: x[0][0] == vals)\n  \n  msgs_reduced = matrices_.join(pred_).mapValues(lambda x: eval(x))\n  final = msgs_reduced.map(lambda x: x[1]).reduce(lambda x, y: x + y)\n  \n  return final\n  \n  \n\n  "],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["pred1 = predictions(a, b, xblock, yblock).persist()\nAUC = modeleval_AUC(pred1, matrices)\nprint AUC\n\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"Cross-sell_v2","notebookId":4275711517901208},"nbformat":4,"nbformat_minor":0}
